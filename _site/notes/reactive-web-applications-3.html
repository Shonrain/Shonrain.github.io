<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1" /><title><译> 响应式 Web 应用（三）</title><meta name="twitter:card" content="summary" /><meta name="twitter:site" content="@HeiswayiNrird" /><meta name="twitter:title" content="<译> 响应式 Web 应用（三）" /><meta name="twitter:description" content="原书"><meta name="description" content="原书"> <script> var _hmt = _hmt || []; (function() { var hm = document.createElement("script"); hm.src = "https://hm.baidu.com/hm.js?2db4617ae1e0a3147b448ffe9d4a4c26"; var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s); })(); </script><link rel="icon" href="/assets/favicon.png"><link rel="apple-touch-icon" href="/assets/touch-icon.png"><style> /* latin-ext */ @font-face { font-family: 'Karla'; font-style: normal; font-weight: 400; src: local('Karla'), local('Karla-Regular'), url(https://fonts.gstatic.com/s/karla/v5/S1bXQ0LrY7AzefpgNae9sYDGDUGfDkXyfkzVDelzfFk.woff2) format('woff2'); unicode-range: U+0100-024F, U+1E00-1EFF, U+20A0-20AB, U+20AD-20CF, U+2C60-2C7F, U+A720-A7FF; } /* latin */ @font-face { font-family: 'Karla'; font-style: normal; font-weight: 400; src: local('Karla'), local('Karla-Regular'), url(https://fonts.gstatic.com/s/karla/v5/JaMH4jmmzP070-OYo03anaCWcynf_cDxXwCLxiixG1c.woff2) format('woff2'); unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215; }</style><link rel="stylesheet" href="/assets/core.css"><link rel="canonical" href="/notes/reactive-web-applications-3"><link rel="alternate" type="application/atom+xml" title="ShawDubie" href="/feed.xml" /> <!-- 多说公共JS代码 start (一个网页只需插入一次) --> <script type="text/javascript"> var duoshuoQuery = {short_name:"shawdubie"}; (function() { var ds = document.createElement('script'); ds.type = 'text/javascript';ds.async = true; ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js'; ds.charset = 'UTF-8'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds); })(); </script> <!-- 多说公共JS代码 end --></head><body><aside class="logo"> <a href="/"> <img src="../assets/img/shaw.jpeg" class="gravatar"> </a> <span class="logo-prompt">Back to Home</span></aside><main> <noscript><style> article .footnotes { display: block; }</style></noscript><article><div class="center"><h1><译> 响应式 Web 应用（三）</h1><time>September 25, 2017</time></div><div class="divider"></div><h2 id="原书">原书</h2><p><a href="http://shawdubie.com/notes/reactive-web-applications-2">上一篇</a></p><h2 id="12-重新思考对计算机资源的利用">1.2 重新思考对计算机资源的利用</h2><p>要理解为什么要采用响应式应用以及响应式应用时怎样的，我们首先需要快速了解一下计算机方面的知识。计算机在过去的几十年中已经进步了许多。特别是在CPU时钟速度（MHz到GHz）和内存（千字节到千兆字节）方面。然而，CPU 内核的数量在不断变化才是过去几年中发生的最大变化，尽管单个 CPU 的时钟速度没有增加。在撰写本文时，大多数计算机至少有4个 CPU 内核，并且已经有供应商能够提供具有1024个内核的 CPU 了。另一方面，计算机的整体架构以及程序的执行机制尚未放生重大变化。因此，这种架构的一些局限性（比如冯·诺依曼的瓶颈）现在已成为一个问题。 要了解这种演变是如何影响 Web 应用程序开发的，我们需要先来看看两个最受欢迎的 Web 服务器体系结构。</p><h3 id="121-基于线程或者事件的-web-应用服务器">1.2.1 基于线程或者事件的 web 应用服务器</h3><p>大致来说，有两种可以用来实现 web 服务器的编程模型，分别是线程模型以及事件模型。在线程模型中，大量的线程负责处理传入的请求。在事件模型中，少量的请求处理线程通过消息传递彼此进行通信。响应式 web 应用服务器采用的是事件模型。</p><h4 id="基于线程模型的服务器">基于线程模型的服务器</h4><p>基于线程的服务器（比如 Apache Tomcat），可以看作是一个有很多个月台的火车站，站长（接收者线程）决定哪列火车（HTTP 请求）到达哪个月台（请求处理线程）。不难看出，有多少个月台，就可以同时接纳多少列火车。下图说明了基于线程的服务器是如何处理 HTTP 请求的。</p><p><img src="../assets/img/Threaded-web-server.png" alt="Image of Threaded web server" /></p><p>顾名思义，基于线程的 web 服务器依赖于在队列中尽可能多的使用线程， 关于火车和线程服务器之间的比较如表1.2所示。</p><p><img src="../assets/img/threaded-web-application-servers-as-train-stations.png" alt="Imgage of threaded web application servers as train stations.png" /></p><h4 id="基于事件模型的服务器">基于事件模型的服务器</h4><p>为了解释事件服务器的工作原理，我们举一个餐厅服务员的例子。</p><p>服务员可以从几个顾客那里接收订单，然后将这些订单交给厨房里的多位厨师。服务员将他们的时间分配给手头上的不同任务，而不用花太多时间在某一个任务上面。他们不需要一次性地处理整个订单，比如：先上酒，然后冷盘，接下来主菜，最后是甜点和浓咖啡。因此，服务员可以高效地一次性服务多张桌子。</p><p>在我写这本书的时候，Play 是基于 Netty 而构建的。当开发人员用 Play 构建应用的时候，开发人员只需要实现厨师“烹饪”响应的行为，而不用去实现服务员的行为，因为这些 Play 已经帮我们实现了。</p><p>基于事件模型的 Web 服务器的机制如下图所示。</p><p><img src="../assets/img/Evented-web-server.png" alt="Image of Evented web server" /></p><p>在事件服务器中，传入的请求被分割成多个事件，这些事件代表了处理整个请求所涉及到的各种较小的任务。例如解析请求主体，从磁盘检索文件或者调用另外一个 web 服务。分割操作是由事件处理程序来完成的，这可能会触发 I/O 操作，进而产生新的事件。例如，你想发送一个请求来获取服务器上文件的大小。在此种情况下，事件处理程序在处理这个请求的时候将会对磁盘进行异步调用。当操作系统计算出文件大小的时候，会发出一个中断，这个中断也就相当于一个新的事件。当轮到这个新事件执行的时候，你就得到了该请求响应的结果——文件的大小。当操作系统在计算文件大小的时候，事件循环程序可以处理队列中的其他事件。</p><p>这种编程模型的一个重要意义就是，在任务上花费的时间应该是很小的。当服务员要上菜的时候，而厨师却坚持要将某一个订单上的全部菜品做完才让服务员去上菜。那么一旦服务员最后从厨房出来，将会看到顾客们一张张生气的面孔。当整个流水线，比如命令或者 HTTP 请求是异步的时候，事件模型才会起作用，她可以使整个流水线能够不被阻塞地去执行。非阻塞 I/O 通常指的是输入-输出操作，这些操作在执行工作时不会占用当前的执行线程，而是在工作完成时发送通知。</p><h4 id="在事件模型服务器以及线程模型服务器上内存的利用率">在事件模型服务器以及线程模型服务器上内存的利用率</h4><p>与线程模型相比，基于事件模型的服务器对硬件资源的利用率要高的多。事件服务器的工作线程只需要几个“服务员”线程就可以处理大量的请求而不用再像线程服务器那样，生成成千上万的“火车轨道”了。使用较少数量的线程有两个好处，分别是减少内存占用和改善性能，因为这样做减少了上下文切换、线程管理的时间以及调度开销。</p><p>在 JVM 上创建的每个线程都有自己的堆栈空间，默认为 1MB。Apache Tomcat 的默认线程池大小为200，这意味着要启动 Apache Tomcat，需要分配超过 200MB 的内存。但是，你仅仅只需要 16MB 就可以将一个 Play 程序跑起来。虽然 200MB 在现在看来不算是一个很大的内存，但是不要忘了，这意味着要想同时处理200条请求就需要 200MB 的内存（这里我们先不考虑在处理这些请求的时候可能会有额外的任务会占用内存的情况），但是如果你想同时满足10000个请求，那么你将需要大量的内存。这种情况并不总是能够满足的，因为依赖于可用的内存，所以线程模型在面对大规模的并发情况时很难去做扩展。并且，线程模型除了使用大量内存之外，还会使 CPU 的效率降低。</p></article><div class="page-navigation"> <a class="home" href="/" title="Back to Homepage">Home</a> <span> &middot; </span> <a class="prev" href="/notes/reactive-web-applications-2" title="PREV: <译> 响应式 Web 应用（二）">&gt;&gt;</a></div></main><div class="footer"> <!-- 多说评论框 start --><div class="ds-thread" data-thread-key="<译> 响应式 Web 应用（三）" data-title="<译> 响应式 Web 应用（三）" data-url="http://shawdubie.com/notes/<译> 响应式 Web 应用（三）"></div><!-- 多说评论框 end --> · <span class="block">Made with &hearts; using <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> &amp; <a href="https://github.com/heiswayi/the-plain" title="The Plain theme by Heiswayi Nrird" target="_blank">The Plain</a> &middot; &lt;/&gt; on <a href="https://github.com/Shonrain" title="Hosted on GitHub" target="_blank">GitHub</a></span> <span class="block">&copy; 2017 ShawDubie</span></div></body></html>